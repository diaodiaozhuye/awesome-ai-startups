{
  "slug": "ollama",
  "name": "Ollama",
  "product_url": "https://hub.docker.com/r/ollama/ollama",
  "description": "The easiest way to get up and running with large language models. ",
  "product_type": "framework",
  "category": "ai-infrastructure",
  "status": "active",
  "meta": {
    "added_date": "2026-02-13",
    "last_updated": "2026-02-13",
    "provenance": {
      "name": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "product_url": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "description": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "product_type": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "category": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "status": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "company.name": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "company.url": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "sub_category": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "tags": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "platforms": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "open_source": {
        "source": "dockerhub",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      }
    }
  },
  "sources": [
    {
      "url": "https://hub.docker.com/r/ollama/ollama",
      "source_name": "dockerhub",
      "scraped_at": "2026-02-13"
    },
    {
      "url": "https://hub.docker.com/r/vllm/vllm-openai",
      "source_name": "dockerhub",
      "scraped_at": "2026-02-12"
    },
    {
      "url": "https://hub.docker.com/r/chromadb/chroma",
      "source_name": "dockerhub",
      "scraped_at": "2026-02-12"
    },
    {
      "url": "https://hub.docker.com/r/qdrant/qdrant",
      "source_name": "dockerhub",
      "scraped_at": "2026-02-12"
    },
    {
      "url": "https://hub.docker.com/r/milvusdb/milvus",
      "source_name": "dockerhub",
      "scraped_at": "2026-02-12"
    },
    {
      "url": "https://hub.docker.com/r/pytorch/pytorch",
      "source_name": "dockerhub",
      "scraped_at": "2026-02-12"
    },
    {
      "url": "https://hub.docker.com/r/tensorflow/tensorflow",
      "source_name": "dockerhub",
      "scraped_at": "2026-02-12"
    },
    {
      "url": "https://hub.docker.com/r/localai/localai",
      "source_name": "dockerhub",
      "scraped_at": "2026-02-12"
    }
  ],
  "company": {
    "name": "Ollama",
    "url": "https://www.bing.com/search?q=Ollama+AI"
  },
  "sub_category": "inference-platform",
  "tags": [
    "docker",
    "open-source",
    "infrastructure"
  ],
  "platforms": [
    "api",
    "cli",
    "desktop"
  ],
  "open_source": true
}
