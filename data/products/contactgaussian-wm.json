{
  "slug": "contactgaussian-wm",
  "name": "ContactGaussian-WM",
  "product_url": "",
  "description": "Developing world models that understand complex physical interactions is essential for advancing robotic planning and simulation.However, existing methods often struggle to accurately model the environment under conditions of data scarcity and complex contact-rich dynamic motion.To address these challenges, we propose ContactGaussian-WM, a differentiable physics-grounded rigid-body world model capable of learning intricate physical laws directly from sparse and contact-rich video sequences.Our framework consists of two core components: (1) a unified Gaussian representation for both visual appearance and collision geometry, and (2) an end-to-end differentiable learning framework that differentiates through a closed-form physics engine to infer physical properties from sparse visual observations.Extensive simulations and real-world evaluations demonstrate that ContactGaussian-WM outperforms state-of-the-art methods in learning complex scenarios, exhibiting robust generalization capabilities.Furthermore, we showcase the practical utility of our framework in downstream applications, including data synthesis and real-time MPC.",
  "product_type": "other",
  "category": "ai-foundation-model",
  "status": "active",
  "meta": {
    "added_date": "2026-02-13",
    "last_updated": "2026-02-12",
    "provenance": {
      "name": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "description": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "product_type": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "category": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "status": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "company.name": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "company.url": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "tags": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "key_people": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "release_date": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      }
    }
  },
  "sources": [
    {
      "url": "http://arxiv.org/abs/2602.11021v1",
      "source_name": "arxiv",
      "scraped_at": "2026-02-13"
    }
  ],
  "company": {
    "name": "ContactGaussian-WM",
    "url": "https://www.bing.com/search?q=ContactGaussian-WM+AI"
  },
  "tags": [
    "nlp",
    "research",
    "real-time",
    "researchers",
    "robotics",
    "computer-vision"
  ],
  "key_people": [
    {
      "name": "Meizhong Wang",
      "title": "Author",
      "is_founder": false
    },
    {
      "name": "Wanxin Jin",
      "title": "Author",
      "is_founder": false
    },
    {
      "name": "Kun Cao",
      "title": "Author",
      "is_founder": false
    },
    {
      "name": "Lihua Xie",
      "title": "Author",
      "is_founder": false
    },
    {
      "name": "Yiguang Hong",
      "title": "Author",
      "is_founder": false
    }
  ],
  "release_date": "2026-02-11"
}
