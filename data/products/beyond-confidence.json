{
  "slug": "beyond-confidence",
  "name": "Beyond Confidence",
  "product_url": "",
  "description": "Large Language Models (LLMs) exhibit impressive capabilities yet suffer from sensitivity to slight input context variations, hampering reliability. Conventional metrics like accuracy and perplexity fail to assess local prediction robustness, as normalized output probabilities can obscure the underlying resilience of an LLM's internal state to perturbations. We introduce the Token Constraint Bound ($δ_{\\mathrm{TCB}}$), a novel metric that quantifies the maximum internal state perturbation an LLM can withstand before its dominant next-token prediction significantly changes. Intrinsically linked to output embedding space geometry, $δ_{\\mathrm{TCB}}$ provides insights into the stability of the model's internal predictive commitment. Our experiments show $δ_{\\mathrm{TCB}}$ correlates with effective prompt engineering and uncovers critical prediction instabilities missed by perplexity during in-context learning and text generation. $δ_{\\mathrm{TCB}}$ offers a principled, complementary approach to analyze and potentially improve the contextual stability of LLM predictions.",
  "product_type": "llm",
  "category": "ai-model",
  "status": "active",
  "meta": {
    "added_date": "2026-02-13",
    "last_updated": "2026-02-13",
    "provenance": {
      "name": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "description": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "product_type": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "category": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "status": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "company.name": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "company.url": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "sub_category": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "tags": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "key_people": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      },
      "release_date": {
        "source": "arxiv",
        "tier": 2,
        "confidence": 0.75,
        "updated_at": "2026-02-13"
      }
    }
  },
  "sources": [
    {
      "url": "http://arxiv.org/abs/2602.10816v1",
      "source_name": "arxiv",
      "scraped_at": "2026-02-13"
    }
  ],
  "company": {
    "name": "Beyond Confidence",
    "url": "https://www.bing.com/search?q=Beyond+Confidence+AI"
  },
  "sub_category": "text-generation",
  "tags": [
    "research",
    "nlp"
  ],
  "key_people": [
    {
      "name": "Deyuan Liu",
      "title": "Author",
      "is_founder": false
    },
    {
      "name": "Zecheng Wang",
      "title": "Author",
      "is_founder": false
    },
    {
      "name": "Zhanyue Qin",
      "title": "Author",
      "is_founder": false
    },
    {
      "name": "Zhiying Tu",
      "title": "Author",
      "is_founder": false
    },
    {
      "name": "Dianhui Chu",
      "title": "Author",
      "is_founder": false
    }
  ],
  "release_date": "2026-02-11"
}
